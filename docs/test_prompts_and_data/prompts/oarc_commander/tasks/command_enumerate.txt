$("command_enumerate")
$("You are a function enumeration specialist for Ollama Agent Roll Cage.")
$("Please provide me with a list of the available Ollama Agent Roll Cage commands, with a breif description of what they do.")
$("The commands for Ollama Agent Roll Cage are as follows:
"/swap": The /swap command in Ollama Agent Roll Cage allows the user to select and swap the current ollama llm model with another ollama llm model.
"/agent select": The /agent select command allows the user to select which agent template should be loaded into, and used by Ollama Agent Roll Cage.
"/voice swap": The /voice swap command the user to select which voice model finetune should loaded into, and used by Ollama Agent Roll Cage.
"/automatic on": The /automatic on command allows the user to turn on the automatic function calling parser the your command response strings to be automatically executed.
"/automatic off": The /automatic off commad allows the user to turn off the automatic function calling parser for your command response strings to no longer be automatically executed.
"/listen on": The /listen on command turns on the speech recognition model.
"/listen off": The /listen off command turns off the speech recognition model.
"/voice on": The /voice on command loads the text to speech model in VRAM or CPU, and allows the user to select which voice model finetune is used for speech generation for Ollama Agent Roll Cage.
"/voice off": The /voice off commadn turns the text to speech generation model off.
"/speech on": The /speech on command activates both the speech recognition, and text to speech generation models, for seemless speech to speech integration.
"/speech off": The /speech off deactivates both the speech recognition, and text to speech generation models, to quit speech to speech mode and enter text to text mode.
"/latex on": The /latex on activates the customTkinter gui for latex formula rendering.
"/latex off": The /latex off deactivates the customTkinter gui for latex formula rendering.
"/llava flow": The /llava flow command allows the user to select which ollama Llava model should be loaded for vision.
"/llava freeze": The /llava freeze deactivates the ollama llava vision model.
"/ollama template": The /ollama template command prints the template file for the currently loaded llm or llava models with ollama.
"/ollama list": The /ollama list command prints the list of ollama models currently downloaded in ollama.
"/ollama loaded": The /ollama loaded command prints the currently loaded ollama models.
"/ollama show": The /ollama show command prints the modelfile for the currently loaded ollama models.
"/ollama license": The /ollama license command prints the license file for the currently loaded ollama model.
If there is a specific command you would like me to execute for you I would be happy to. Just say "Please run the command for..." or "Please {insert_request_command_description}" or "Only Respond with the command for..." and I will respond with the necessary command string to be parsed out by Ollama Agent Roll Cage and executed by the program.
Feel free to try different requests! My training is modular and I have a deep understanding of the interconnectedness of the Ollama Agent Roll Cage commands. You can even request multiple function calls and I will do my best to build the execution list for a multiple command calling task, such as "/listen on /llava flow" would be multiple commands that will be parsed and executed one by one in the order they are devised. 
")